{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "big_data_platforms_nlp_trending_data_part_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNCyH9naljen",
        "outputId": "9cd47912-2657-4ac9-bf61-b43dc8f11fc2"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!pip install yake"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-27 18:17:07--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-11-27 18:17:07--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-11-27 18:17:08--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-27 18:17:08 (64.4 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 52 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 61.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 72.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting jellyfish\n",
            "  Downloading jellyfish-0.8.9.tar.gz (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.19.5)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2019.12.20)\n",
            "Building wheels for collected packages: jellyfish, segtok\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.8.9-cp37-cp37m-linux_x86_64.whl size=73220 sha256=3fd5379dcf811c48fb0a7bef287ba54a46f08a920e33320f8010d62f09234b24\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/a9/ef/5d8742e72deaf0d1de327a180d008c2c0299367581800ea73f\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=4294ea14617011cc378f411739319258124356082ca536cb5b3a38b30d9076a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "Successfully built jellyfish segtok\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.8.9 segtok-1.5.10 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VPgXn60lqEv",
        "outputId": "ad380665-01a7-46e2-ecc3-0a397e113c3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gtEWPcZ0z4"
      },
      "source": [
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKLArWXZZ3k5"
      },
      "source": [
        "#!unzip '/content/drive/MyDrive/all_the_news.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtwS5-xLl_Yt"
      },
      "source": [
        "from glob import glob\n",
        "fp = [f for f in glob('/content/drive/**', recursive=True) if 'youtube_clean_' in f and '.json' in f][0]\n",
        "fp_news = '/content/drive/MyDrive/all-the-news-2-1.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZA3H0KMoKNx"
      },
      "source": [
        "import sparknlp\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\")\\\n",
        "    .master(\"local[4]\")\\\n",
        "    .config(\"spark.driver.memory\",\"16G\")\\\n",
        "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\")\\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa0pXW3bzmOe"
      },
      "source": [
        "from pyspark.sql.functions import col, year, month, udf, concat, explode\n",
        "from pyspark.sql.types import StringType, ArrayType"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAj903tofOXi"
      },
      "source": [
        "preprocess_article = udf(lambda x: pre_process(x), ArrayType(StringType()) )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPj4qtRyc2yh",
        "outputId": "23437e4d-1479-463b-ca2c-7d722fa36280"
      },
      "source": [
        "news = spark.read.format(\"org.apache.spark.csv\").option(\"multiline\", \"true\").csv(fp_news, inferSchema=True, header=True, quote='\"', sep = \",\", escape='\\\"')\n",
        "news.show(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------------------+----+-----+---+-----------+--------------------+--------------------+--------------------+-------+----------------+\n",
            "|_c0|Unnamed: 0|               date|year|month|day|     author|               title|             article|                 url|section|     publication|\n",
            "+---+----------+-------------------+----+-----+---+-----------+--------------------+--------------------+--------------------+-------+----------------+\n",
            "|  0|         0|2016-12-09 18:31:00|2016| 12.0|  9|Lee Drutman|We should take co...|This post is part...|https://www.vox.c...|   null|             Vox|\n",
            "|  1|         1|2016-10-07 21:26:46|2016| 10.0|  7|Scott Davis|Colts GM Ryan Gri...| The Indianapolis...|https://www.busin...|   null|Business Insider|\n",
            "|  2|         2|2018-01-26 00:00:00|2018|  1.0| 26|       null|Trump denies repo...|DAVOS, Switzerlan...|https://www.reute...|  Davos|         Reuters|\n",
            "+---+----------+-------------------+----+-----+---+-----------+--------------------+--------------------+--------------------+-------+----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFlRNoup1fl5"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4DDxjvB0Lu-"
      },
      "source": [
        "document_assembler = DocumentAssembler().setInputCol('article').setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document']) \\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols(['sentences']) \\\n",
        "    .setOutputCol('tokens') \\\n",
        "    .setContextChars(['(', ')', '?','!','.',','])\n",
        "\n",
        "keywords = YakeKeywordExtraction() \\\n",
        "    .setInputCols('tokens') \\\n",
        "    .setOutputCol('keywords') \\\n",
        "    .setMinNGrams(2) \\\n",
        "    .setMaxNGrams(5) \\\n",
        "    .setNKeywords(5) \\\n",
        "    .setStopWords(StopWordsCleaner().getStopWords())\n",
        "\n",
        "\n",
        "pipeline_news = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    keywords,\n",
        "])\n",
        "model_pipeline = pipeline_news.fit(news)\n",
        "news_transformed = model_pipeline.transform(news)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppttzNQq8AnV"
      },
      "source": [
        "extract_keywords = udf(lambda x: list(set([j.result for j in x])), ArrayType(StringType()))\n",
        "news_transformed = news_transformed.withColumn('keywords_only', extract_keywords(news_transformed.keywords ))\n",
        "news_transformed = news_transformed.withColumn('month', news_transformed.month.cast('integer'))\n",
        "news_transformed = news_transformed.withColumn('year_month', concat(news_transformed.year, news_transformed.month ))\n",
        "news_transformed_exploded = news_transformed.select(news_transformed.year_month, explode(news_transformed.keywords_only))\n",
        "news_transformed_keyword_count = news_transformed_exploded.groupBy(['year_month','col']).count()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM8RS11CoWS7",
        "outputId": "dc1a50ac-7954-494a-91ab-353d22c7f262"
      },
      "source": [
        "news_transformed_keyword_count.show(3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-----+\n",
            "|year_month|               col|count|\n",
            "+----------+------------------+-----+\n",
            "|     20196|benoit coeure said|    5|\n",
            "|     20162| republican senate|   11|\n",
            "|     20174|   united airlines|  208|\n",
            "+----------+------------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXxlKJ-Izl1w"
      },
      "source": [
        "news_transformed_keyword_count.coalesce(1).write.format('json').save('/content/drive/MyDrive/news_keywords_count.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}