{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: KMonzella <br>\n",
    "Date: 2021/11/06 <br>\n",
    "Subject: Data Cleaning in Spark <br>\n",
    "Overview: In our 02 program, we pulled our YouTube data from links generated in earlier programs. We are now going to perform preliminary data cleaning on the raw files and output clean analysis files with all constructs except some NLP-based constructs which will be generated separately.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Program setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://md01.rcc.local:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0-cdh6.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f49b28d54a8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import seaborn               as sns\n",
    "from   scipy                 import stats\n",
    "from pyspark.sql.functions   import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types       import IntegerType,BooleanType,DateType\n",
    "from pyspark.sql.functions   import rank, col,approxCountDistinct, countDistinct\n",
    "\n",
    "#change configuration settings on Spark \n",
    "spark = SparkSession.builder.appName('SparkBasics').getOrCreate()\n",
    "\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '200g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '8'), ('spark.cores.max', '8'), ('spark.driver.memory','30g')])\n",
    "\n",
    "#print spark configuration settings\n",
    "sc   = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in CSV input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 ms, sys: 3.04 ms, total: 11.7 ms\n",
      "Wall time: 36.8 s\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- publish_date: string (nullable = true)\n",
      " |-- watch_url: string (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- metadata: string (nullable = true)\n",
      " |-- stream_info: string (nullable = true)\n",
      " |-- age_restricted: string (nullable = true)\n",
      " |-- length: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- transcript: string (nullable = true)\n",
      " |-- language_detected: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time df = spark.read.format(\"org.apache.spark.csv\").option(\"multiline\", \"true\").csv(\"/user/kmonzella/data/youtube_raw_20211120.csv\", inferSchema=True, header=True, quote='\\\"', sep = \",\", escape='\"')\n",
    "df.printSchema() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------+--------------------+--------------+------+------+--------------------+-----+--------------------+-----------------+\n",
      "|_c0|              author|             channel|         description|publish_date|           watch_url|            keywords|metadata|         stream_info|age_restricted|length|rating|               title|views|          transcript|language_detected|\n",
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------+--------------------+--------------+------+------+--------------------+-----+--------------------+-----------------+\n",
      "|  0|What Does That Mean?|UCS3RXL1ICt42KV-E...|What does proleta...|    20150105|https://youtube.c...|proletarianism|de...|      []|[<Stream: itag=\"1...|         FALSE|    59|     1|What does proleta...|  174|What does proleta...|               en|\n",
      "|  1|Caacrinolaas - Topic|UCehqr_BtweZ9Al7a...|Provided to YouTu...|    20180609|https://youtube.c...|Caacrinolaas|Giac...|      []|[<Stream: itag=\"1...|         FALSE|   197|     0|      Proletarianism|   55|No transcript ava...|               id|\n",
      "|  2|         TES - Randy|UCW9mpfvO5t3KY0vD...|At least we still...|    20210105|https://youtube.c...|                null|      []|[<Stream: itag=\"1...|         FALSE|     5|     5|Provisional Probl...|  163|wow i love this n...|               en|\n",
      "+---+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------+--------------------+--------------+------+------+--------------------+-----+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check what data look like\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total record count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preliminary cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['watch_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376842"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check for other missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "|_c0|author|channel|description|publish_date|watch_url|keywords|metadata|stream_info|age_restricted|length|rating|title|views|transcript|language_detected|\n",
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "|  0|     6|      1|      33952|           1|        1|   93444|       6|          7|             8|     9|    10|   13|   12|        33|                0|\n",
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missingness\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are the overflow from the cut off transcripts. As long as this is low prevalence, drop\n",
    "percent_nonmissing = df.filter(df.watch_url.startswith('https://youtube.com/watch?v=')).count() * 100 / df.count()\n",
    "print(percent_nonmissing)\n",
    "\n",
    "df1 = df.filter(df.watch_url.startswith('https://youtube.com/watch?v='))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "|_c0|author|channel|description|publish_date|watch_url|keywords|metadata|stream_info|age_restricted|length|rating|title|views|transcript|language_detected|\n",
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "|  0|     5|      0|      33951|           0|        0|   93440|       1|          1|             1|     1|     1|    2|    1|        22|                0|\n",
      "+---+------+-------+-----------+------------+---------+--------+--------+-----------+--------------+------+------+-----+-----+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recheck missingness\n",
    "df1.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df1.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address other missingness - transcripts\n",
    "\n",
    "df1 = df1.withColumn(\"transcript\", f.when(col(\"transcript\")=='No transcript available', None).otherwise(col(\"transcript\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          transcript|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|hey what's up guy...|\n",
      "|Oh hey guys move ...|\n",
      "|                null|\n",
      "|[Music] [Music] [...|\n",
      "|should I there gu...|\n",
      "|                null|\n",
      "|                null|\n",
      "|[Music] welcome t...|\n",
      "|                null|\n",
      "|the last couple o...|\n",
      "|hey everyone welc...|\n",
      "|[Music] hello eve...|\n",
      "|hey what's up you...|\n",
      "|EMCEE: And now fo...|\n",
      "|well we're going ...|\n",
      "|                null|\n",
      "|hey this is tom a...|\n",
      "|or the table mate...|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(\"transcript\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Check and change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- numeric\n",
    "\n",
    "cols = [\"length\", \"rating\", \"views\"]\n",
    "for col in cols:\n",
    "    df1 = df1.withColumn(\n",
    "            col,\n",
    "            f.col(col).cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|publish_date|publish_date_new|\n",
      "+------------+----------------+\n",
      "|    20170207|      2017-02-07|\n",
      "|    20210906|      2021-09-06|\n",
      "|    20110916|      2011-09-16|\n",
      "|    20211001|      2021-10-01|\n",
      "|    20211109|      2021-11-09|\n",
      "|    20141109|      2014-11-09|\n",
      "|    20121211|      2012-12-11|\n",
      "|    20170114|      2017-01-14|\n",
      "|    20210319|      2021-03-19|\n",
      "|    20180920|      2018-09-20|\n",
      "+------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --- dates\n",
    "\n",
    "df1 = df1.withColumn(\"publish_date_new\", to_date(\"publish_date\", \"yyyyMMdd\"))\n",
    "\n",
    "print(df1.select([\"publish_date\", \"publish_date_new\"]).show(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(\"publish_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- booleans\n",
    "\n",
    "df1 = df1.withColumn(\"age_restricted\",  df1.age_restricted.cast(BooleanType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create new variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Indicators of whether there is a song in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"has_music\", f.when(f.col(\"metadata\").contains('Song'), 1.0).otherwise(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|has_music|            metadata|\n",
      "+---------+--------------------+\n",
      "|      1.0|[{\"Song\": \"Broad ...|\n",
      "|      1.0|[{\"Song\": \"Dead H...|\n",
      "|      1.0|[{\"Song\": \"First ...|\n",
      "|      1.0|[{\"Song\": \"Africa...|\n",
      "|      1.0|[{\"Song\": \"Runnin...|\n",
      "|      1.0|[{\"Song\": \"19th F...|\n",
      "|      1.0|[{\"Song\": \"Chills...|\n",
      "|      1.0|[{\"Song\": \"Ankara...|\n",
      "|      1.0|[{\"Song\": \"My Swe...|\n",
      "|      1.0|[{\"Song\": \"Half E...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------+--------+\n",
      "|has_music|metadata|\n",
      "+---------+--------+\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "|      0.0|      []|\n",
      "+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(\"has_music==1\").select([\"has_music\", \"metadata\"]).show(10)\n",
    "df1.filter(\"has_music==0\").select([\"has_music\", \"metadata\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|has_sounds|          transcript|\n",
      "+----------+--------------------+\n",
      "|       1.0|hey what's up guy...|\n",
      "|       1.0|[Music] [Music] [...|\n",
      "|       1.0|[Music] welcome t...|\n",
      "|       1.0|the last couple o...|\n",
      "|       1.0|hey everyone welc...|\n",
      "|       1.0|[Music] hello eve...|\n",
      "|       1.0|you go aiden you'...|\n",
      "|       1.0|[Music] welcome b...|\n",
      "|       1.0|[Music] do [Music...|\n",
      "|       1.0|game one on the r...|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|has_sounds|          transcript|\n",
      "+----------+--------------------+\n",
      "|       0.0|                null|\n",
      "|       0.0|Oh hey guys move ...|\n",
      "|       0.0|                null|\n",
      "|       0.0|should I there gu...|\n",
      "|       0.0|                null|\n",
      "|       0.0|                null|\n",
      "|       0.0|                null|\n",
      "|       0.0|hey what's up you...|\n",
      "|       0.0|EMCEE: And now fo...|\n",
      "|       0.0|well we're going ...|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transcript has sound effects\n",
    "df1 = df1.withColumn(\"has_sounds\", f.when(f.col(\"transcript\").contains('[Music]'), 1.0).otherwise(0.0))\n",
    "df1.filter(\"has_sounds==1\").select([\"has_sounds\", \"transcript\"]).show(10)\n",
    "df1.filter(\"has_sounds==0\").select([\"has_sounds\", \"transcript\"]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Indicators related to streaming quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed at this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Indicators related to duration - binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"duration_long\",   f.when(f.col('length') >= 1800, 1).otherwise(0))\n",
    "df1 = df1.withColumn(\"duration_med\",    f.when((f.col('length') < 1800) & (f.col('length')>=600), 1).otherwise(0))\n",
    "df1 = df1.withColumn(\"duration_short\",  f.when(f.col('length') < 600,   1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+--------------+\n",
      "| length|duration_long|duration_med|duration_short|\n",
      "+-------+-------------+------------+--------------+\n",
      "| 3245.0|            1|           0|             0|\n",
      "| 7754.0|            1|           0|             0|\n",
      "| 7211.0|            1|           0|             0|\n",
      "| 4827.0|            1|           0|             0|\n",
      "|19903.0|            1|           0|             0|\n",
      "| 5708.0|            1|           0|             0|\n",
      "| 5558.0|            1|           0|             0|\n",
      "| 2108.0|            1|           0|             0|\n",
      "| 6177.0|            1|           0|             0|\n",
      "| 5550.0|            1|           0|             0|\n",
      "| 3113.0|            1|           0|             0|\n",
      "| 5182.0|            1|           0|             0|\n",
      "| 3685.0|            1|           0|             0|\n",
      "| 2664.0|            1|           0|             0|\n",
      "| 2886.0|            1|           0|             0|\n",
      "|68199.0|            1|           0|             0|\n",
      "| 3539.0|            1|           0|             0|\n",
      "|42897.0|            1|           0|             0|\n",
      "| 2077.0|            1|           0|             0|\n",
      "| 2163.0|            1|           0|             0|\n",
      "+-------+-------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------------+------------+--------------+\n",
      "|length|duration_long|duration_med|duration_short|\n",
      "+------+-------------+------------+--------------+\n",
      "|  81.0|            0|           0|             1|\n",
      "| 714.0|            0|           1|             0|\n",
      "| 326.0|            0|           0|             1|\n",
      "| 813.0|            0|           1|             0|\n",
      "|1260.0|            0|           1|             0|\n",
      "| 262.0|            0|           0|             1|\n",
      "| 308.0|            0|           0|             1|\n",
      "| 315.0|            0|           0|             1|\n",
      "|1595.0|            0|           1|             0|\n",
      "| 211.0|            0|           0|             1|\n",
      "| 437.0|            0|           0|             1|\n",
      "| 651.0|            0|           1|             0|\n",
      "|  55.0|            0|           0|             1|\n",
      "| 235.0|            0|           0|             1|\n",
      "| 205.0|            0|           0|             1|\n",
      "|  38.0|            0|           0|             1|\n",
      "| 262.0|            0|           0|             1|\n",
      "| 899.0|            0|           1|             0|\n",
      "| 504.0|            0|           0|             1|\n",
      "| 222.0|            0|           0|             1|\n",
      "+------+-------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(\"duration_long==1\").select([\"length\", \"duration_long\", \"duration_med\", \"duration_short\"]).show()\n",
    "df1.filter(\"duration_long==0\").select([\"length\", \"duration_long\", \"duration_med\", \"duration_short\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of keywords - perhaps more search terms helps you get more views\n",
    "df1 = df1.withColumn('n_keywords', f.size(f.split(f.col(\"keywords\"), r\"\\|\")) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            keywords|n_keywords|\n",
      "+--------------------+----------+\n",
      "|                null|         0|\n",
      "|paranormal activi...|         9|\n",
      "|undulation|belly ...|        45|\n",
      "|Goodzik|Removal o...|        25|\n",
      "|Mopar 1968 1969 1...|         2|\n",
      "|                null|         0|\n",
      "|Johnny Conga|Cong...|         9|\n",
      "|What is Optics|ex...|        17|\n",
      "|                null|         0|\n",
      "|                null|         0|\n",
      "|speed ramping tut...|        20|\n",
      "|saul|saul lopez|s...|        24|\n",
      "|how to pronounce ...|         9|\n",
      "|AndyHafell|make m...|        19|\n",
      "|lifetime|mylifeti...|        30|\n",
      "|                null|         0|\n",
      "|affair|movies|PRI...|        32|\n",
      "|TSLA|TESLA|TESLA ...|        13|\n",
      "|QVC|V36076|For th...|         6|\n",
      "|#RHCHEMISTRY|#RH|...|        23|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select([\"keywords\", \"n_keywords\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|post_covid|publish_date_new|\n",
      "+----------+----------------+\n",
      "|         0|      2017-02-07|\n",
      "|         1|      2021-09-06|\n",
      "|         0|      2011-09-16|\n",
      "|         1|      2021-10-01|\n",
      "|         1|      2021-11-09|\n",
      "|         0|      2014-11-09|\n",
      "|         0|      2012-12-11|\n",
      "|         0|      2017-01-14|\n",
      "|         1|      2021-03-19|\n",
      "|         0|      2018-09-20|\n",
      "|         0|      2018-09-04|\n",
      "|         1|      2020-07-21|\n",
      "|         1|      2020-11-01|\n",
      "|         1|      2021-10-27|\n",
      "|         0|      2018-07-15|\n",
      "|         0|      2018-01-08|\n",
      "|         0|      2015-02-07|\n",
      "|         1|      2021-10-12|\n",
      "|         0|      2019-02-08|\n",
      "|         1|      2021-11-03|\n",
      "+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- post covid \n",
    "\n",
    "# create a covid inicator. Assume official start of COVID-19 pandemic as March 27, 2020 \n",
    "# this is the date the CARES act was implemented\n",
    "df1 = df1.withColumn('post_covid', f.when(f.col('publish_date_new') > \"2020-03-26\", 1).otherwise(0))\n",
    "df1.select([\"post_covid\", \"publish_date_new\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+\n",
      "|min(n_posts_by_author)|max(n_posts_by_author)|\n",
      "+----------------------+----------------------+\n",
      "|                     0|                   630|\n",
      "+----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window.partitionBy('author')\n",
    "df1 = df1.withColumn('n_posts_by_author', f.count('author').over(w))\n",
    "df1.agg(f.min(f.col(\"n_posts_by_author\")),  f.max(f.col(\"n_posts_by_author\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+\n",
      "|min(n_posts_by_channel)|max(n_posts_by_channel)|\n",
      "+-----------------------+-----------------------+\n",
      "|                      1|                    627|\n",
      "+-----------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = Window.partitionBy('channel')\n",
    "df1 = df1.withColumn('n_posts_by_channel', f.count('channel').over(w))\n",
    "df1.agg(f.min(f.col(\"n_posts_by_channel\")),  f.max(f.col(\"n_posts_by_channel\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|              author|n_posts_by_author|\n",
      "+--------------------+-----------------+\n",
      "|                null|                0|\n",
      "|                null|                0|\n",
      "|                null|                0|\n",
      "|                null|                0|\n",
      "|                null|                0|\n",
      "|       ! Hadookaan !|                1|\n",
      "|\"M��nnerabend - D...|                1|\n",
      "|\"The Voodoo King\"...|                4|\n",
      "|\"The Voodoo King\"...|                4|\n",
      "|\"The Voodoo King\"...|                4|\n",
      "|\"The Voodoo King\"...|                4|\n",
      "|\"You are First\" b...|                1|\n",
      "|      # Chen Jialing|                1|\n",
      "|            # DUBBIC|                1|\n",
      "| # Don���t Trust Bro|                1|\n",
      "|# UMESH RAUT | VA...|                1|\n",
      "|             # eRRoR|                1|\n",
      "|    #1 Marmaduke Fan|                2|\n",
      "|    #1 Marmaduke Fan|                2|\n",
      "| #1 in ESL Practice!|                1|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.sort(\"author\").select([\"author\", \"n_posts_by_author\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Transformations to outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|views_high|    views|\n",
      "+----------+---------+\n",
      "|         0|      1.0|\n",
      "|         1|  70211.0|\n",
      "|         1|  13210.0|\n",
      "|         1| 117918.0|\n",
      "|         0|    262.0|\n",
      "|         0|     15.0|\n",
      "|         0|   2369.0|\n",
      "|         1|  60554.0|\n",
      "|         0|     55.0|\n",
      "|         0|     11.0|\n",
      "|         0|    493.0|\n",
      "|         0|   8467.0|\n",
      "|         0|      3.0|\n",
      "|         0|      4.0|\n",
      "|         1|4741684.0|\n",
      "|         0|   6001.0|\n",
      "|         0|   1909.0|\n",
      "|         1| 121606.0|\n",
      "|         0|   1499.0|\n",
      "|         1|  49239.0|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.withColumn('views_high', f.when(f.col('views') > 10000, 1).otherwise(0))\n",
    "df1.select([\"views_high\", \"views\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|views_cat|    views|\n",
      "+---------+---------+\n",
      "|        3|  70211.0|\n",
      "|        3|  13210.0|\n",
      "|        3| 117918.0|\n",
      "|        3|  60554.0|\n",
      "|        3|4741684.0|\n",
      "|        3| 121606.0|\n",
      "|        3|  49239.0|\n",
      "|        3|  22499.0|\n",
      "|        3| 104235.0|\n",
      "|        3| 333510.0|\n",
      "+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------+------+\n",
      "|views_cat| views|\n",
      "+---------+------+\n",
      "|        2|2369.0|\n",
      "|        2|8467.0|\n",
      "|        2|6001.0|\n",
      "|        2|1909.0|\n",
      "|        2|1499.0|\n",
      "|        2|1671.0|\n",
      "|        2|4063.0|\n",
      "|        2|4696.0|\n",
      "|        2|5005.0|\n",
      "|        2|1885.0|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------+-----+\n",
      "|views_cat|views|\n",
      "+---------+-----+\n",
      "|        1|  1.0|\n",
      "|        1|262.0|\n",
      "|        1| 15.0|\n",
      "|        1| 55.0|\n",
      "|        1| 11.0|\n",
      "|        1|493.0|\n",
      "|        1|  3.0|\n",
      "|        1|  4.0|\n",
      "|        1|  7.0|\n",
      "|        1| 73.0|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical views - high medium low\n",
    "df1 = df1.withColumn(\"views_cat\", f.when(f.col('views') > 10000, 3).otherwise(\n",
    "     f.when(f.col(\"views\") > 1000, 2).otherwise(1)))\n",
    "    \n",
    "df1.filter(\"views_cat==3\").select([\"views_cat\", \"views\"]).show(10)\n",
    "df1.filter(\"views_cat==2\").select([\"views_cat\", \"views\"]).show(10)\n",
    "df1.filter(\"views_cat==1\").select([\"views_cat\", \"views\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+\n",
      "|min(views)|   max(views)|        avg(views)|\n",
      "+----------+-------------+------------------+\n",
      "|       0.0|7.606261432E9|2938761.1831926527|\n",
      "+----------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check min, max, median, and average values for references\n",
    "df1.agg(f.min(f.col(\"views\")), f.max(f.col(\"views\")), f.avg(f.col(\"views\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Output df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- watch_url: string (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      " |-- metadata: string (nullable = true)\n",
      " |-- stream_info: string (nullable = true)\n",
      " |-- age_restricted: boolean (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- views: double (nullable = true)\n",
      " |-- transcript: string (nullable = true)\n",
      " |-- language_detected: string (nullable = true)\n",
      " |-- publish_date_new: date (nullable = true)\n",
      " |-- has_music: double (nullable = false)\n",
      " |-- has_sounds: double (nullable = false)\n",
      " |-- duration_long: integer (nullable = false)\n",
      " |-- duration_med: integer (nullable = false)\n",
      " |-- duration_short: integer (nullable = false)\n",
      " |-- n_keywords: integer (nullable = false)\n",
      " |-- post_covid: integer (nullable = false)\n",
      " |-- n_posts_by_author: long (nullable = false)\n",
      " |-- n_posts_by_channel: long (nullable = false)\n",
      " |-- views_high: integer (nullable = false)\n",
      " |-- views_cat: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 ms, sys: 5.94 ms, total: 20.1 ms\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%time df1.coalesce(1).write.mode('overwrite').option('header','true').csv('/user/kmonzella/data/youtube_clean.csv')\n",
    "\n",
    "#hdfs dfs -copyToLocal /user/kmonzella/data/youtube_clean.csv ~/data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
